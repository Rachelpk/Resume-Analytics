{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Spacy Model\n",
    "import spacy\n",
    "#Spacy Model For identifying titles\n",
    "import Model_50\n",
    "#Importing Displacy\n",
    "from spacy import displacy\n",
    "#For Dates and Duration calculation\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "from datetime import date\n",
    "import re\n",
    "import datetime\n",
    "import dateutil.parser as dparser\n",
    "import datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For finding the path of our folder\n",
    "import json\n",
    "import os\n",
    "import inspect\n",
    "import sys\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for extracting content from the pdfs\n",
    "import pdfminer.settings\n",
    "import six\n",
    "import io\n",
    "pdfminer.settings.STRICT = False\n",
    "import pdfminer.layout\n",
    "from pdfminer.image import ImageWriter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LTTextBoxHorizontal\n",
    "from pdfminer.layout import LTChar\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "nlp_title = spacy.load('Model_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spacy_Identified(text,nlp,line_number):\n",
    "    return(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_if_work_experience_available(file_path,nlp,start_time):\n",
    "    \n",
    "    #Line number\n",
    "    line_number = 0\n",
    "    \n",
    "    #Checking whether the work experience section is available\n",
    "    counter_header = 0\n",
    "    \n",
    "    #If available, We have to assign the starting line number and ending line number to it for easy access\n",
    "    line_number_start = 0\n",
    "    line_number_end = 0\n",
    "    \n",
    "    #Opening the document\n",
    "    document = open(file_path, 'rb')\n",
    "    \n",
    "    #Create resource manager\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    \n",
    "    # Set parameters for analysis.\n",
    "    #line_overlap=0.5, char_margin=2.0, line_margin=0.5, word_margin=0.1, boxes_flow=0.5,detect_vertical=False, all_texts=False\n",
    "    laparams = LAParams(line_overlap=0.5, char_margin=50.0, line_margin=0.5,word_margin=0.1, boxes_flow=0.5,\n",
    "                         detect_vertical=False, all_texts=False)\n",
    "    \n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    for page in PDFPage.get_pages(document,caching=True,check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "        # receive the LTPage object for the page.\n",
    "        layout = device.get_result()\n",
    "        for element in layout:\n",
    "            line_number+=1\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                text=element.get_text()\n",
    "                text_nlp=nlp_title(text)  \n",
    "                \n",
    "                for t in text_nlp.ents:\n",
    "                    if t.label_ == 'WORK_EXP_HEADING':\n",
    "                        counter_header = 1\n",
    "                        line_number_start = line_number\n",
    "                        \n",
    "                    elif t.label_ == 'HEADING':\n",
    "                        if(counter_header == 1):\n",
    "                            line_number_end = line_number\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return(counter_header, line_number_start, line_number_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dealing_with_work_experience_heading(line_number_start,line_number_end,file_path,start_time):\n",
    "    \n",
    "    #Line number initialization\n",
    "    line_number = 0\n",
    "    List_Org = []\n",
    "    \n",
    "    #print(\"Converting PDF to Text to extract features\")\n",
    "    document = open(file_path, 'rb')\n",
    "    #Create resource manager\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    # Set parameters for analysis.\n",
    "    laparams = LAParams(line_overlap=0.5, char_margin=50.0, line_margin=0.5,word_margin=0.1, boxes_flow=0.5,\n",
    "                         detect_vertical=False, all_texts=False)\n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    for page in PDFPage.get_pages(document,caching=True,check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "        # receive the LTPage object for the page.\n",
    "        layout = device.get_result()\n",
    "        for element in layout:\n",
    "            line_number+=1\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                text=element.get_text()\n",
    "                if(line_number >= line_number_start and line_number <= line_number_end):\n",
    "                    text=nlp_title(text)\n",
    "                    lis=Spacy_Identified(text,nlp_title,line_number)\n",
    "                    if(lis != None):\n",
    "                        List_Org.append(lis)\n",
    "\n",
    "    flatten=[l for subitem in List_Org for l in subitem]\n",
    "    for l in flatten:\n",
    "        year=calculate_duration(l[1])\n",
    "        l[1].append(year)\n",
    "        \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    return(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dealing_with_no_work_experience_heading(file_path):\n",
    "    line_number = 0\n",
    "    List_Org = list()\n",
    "    document = open(file_path, 'rb')\n",
    "    #Create resource manager\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    # Set parameters for analysis.\n",
    "    laparams = LAParams(line_overlap=0.5, char_margin=50.0, line_margin=0.5,word_margin=0.1, boxes_flow=0.5,\n",
    "                         detect_vertical=False, all_texts=False)\n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    for page in PDFPage.get_pages(document,caching=True,check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "        # receive the LTPage object for the page.\n",
    "        layout = device.get_result()\n",
    "        for element in layout:\n",
    "            line_number+=1\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                text=element.get_text()\n",
    "                text=nlp_title(text)  \n",
    "                lis=Spacy_Identified(text,nlp_title,line_number)\n",
    "                if(lis != None):\n",
    "                    List_Org.append(lis)  \n",
    "    flatten=[l for subitem in List_Org for l in subitem]\n",
    "    for l in flatten:\n",
    "        year=calculate_duration(l[1])\n",
    "        l[1].append(year)\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for converting pdf to text\n",
    "def convert_pdf_to_text(file_path,nlp):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    counter, line_number_start, line_number_end = find_if_work_experience_available(file_path,nlp,start_time)\n",
    "    \n",
    "    if(counter == 1):\n",
    "        score_1 = dealing_with_work_experience_heading(line_number_start,line_number_end,file_path,start_time)\n",
    "    elif(counter == 0):\n",
    "        score_1 = dealing_with_no_work_experience_heading(file_path)\n",
    "        \n",
    "    print(\"Score_1 for the resume: \", score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.729592561721802 seconds ---\n",
      "--- 9.174578666687012 seconds ---\n",
      "Score_1 for the resume:  0\n"
     ]
    }
   ],
   "source": [
    "convert_pdf_to_text(\"/data/home/devuser/Talenthub - Resume Analytics/July/Resumes_Test/Swathi's_Resume.pdf\",nlp_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
